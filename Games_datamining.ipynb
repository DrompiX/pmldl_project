{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Games_datamining.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyWg5LxpfXAd",
        "colab_type": "code",
        "outputId": "819b8700-de0e-40b1-f16e-594cabed5966",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86rRuoibxRjH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import scipy.io\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "from time import sleep\n",
        "import timeit\n",
        "import sqlite3\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkIFp7FryGft",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def req(msg, slp=0.2):\n",
        "    \"\"\"Make fault tolerant BGG server requests.\"\"\"\n",
        "    # Sleep to make sure you are not pinging the server to frequently\n",
        "    sleep(slp)\n",
        "    # Keep trying requests until status-code is 200\n",
        "    status_code = 500\n",
        "    while status_code != 200:\n",
        "        sleep(slp)\n",
        "        try:\n",
        "            r = requests.get(msg)\n",
        "            status_code = r.status_code\n",
        "            # if status_code != 200:\n",
        "                # print(\"Server Error! Response Code %i. Retrying...\" % (r.status_code))\n",
        "        except:\n",
        "            # print(\"An exception has occurred, probably a momentory loss of connection. Waiting three seconds...\")\n",
        "            sleep(3)\n",
        "    return r"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHAfs6NQyNZr",
        "colab_type": "code",
        "outputId": "2bd6d02f-fdd7-4b76-963e-bc098435a2d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "r = requests.get(\"http://www.boardgamegeek.com/xmlapi2/user?name=Zazz&top=1\")\n",
        "soup = BeautifulSoup(r.text, \"xml\")  # Use the xml parser for API responses and the html_parser for scraping\n",
        "print(r.status_code)  # 404 not found and the like. Hopefully 200!"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDc1a2I1yT4G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def request(msg, slp=1):\n",
        "    '''A wrapper to make robust https requests.'''\n",
        "    status_code = 500  # Want to get a status-code of 200\n",
        "    while status_code != 200:\n",
        "        sleep(slp)  # Don't ping the server too often\n",
        "        try:\n",
        "            r = requests.get(msg)\n",
        "            status_code = r.status_code\n",
        "            if status_code != 200:\n",
        "                print(\"Server Error! Response Code %i. Retrying...\" % (r.status_code))\n",
        "        except:\n",
        "            print(\"An exception has occurred, probably a momentory loss of connection. Waiting one seconds...\")\n",
        "            sleep(1)\n",
        "    return r"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGaIFRrXyrb8",
        "colab_type": "code",
        "outputId": "b0b60e40-5b8b-454c-bbe9-7ef5a968f034",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# Initialize a DF to hold all our scraped game info\n",
        "df_all = pd.DataFrame(columns=[\"id\", \"name\", \"nrate\", \"pic_url\"])\n",
        "min_nrate = 1e5\n",
        "npage = 1\n",
        "i = 0\n",
        "\n",
        "# Scrap successful pages in the results until we get down to games with < 1000 ratings each\n",
        "while i <= 400:\n",
        "    # Get full HTML for a specific page in the full listing of boardgames sorted by \n",
        "    r = request(\"https://boardgamegeek.com/browse/boardgame/page/%i?sort=numvoters&sortdir=desc\" % (npage,))\n",
        "    soup = BeautifulSoup(r.text, \"html.parser\")    \n",
        "    \n",
        "    # Get rows for the table listing all the games on this page\n",
        "    table = soup.find_all(\"tr\", attrs={\"id\": \"row_\"})  # Get list of all the rows (tags) in the list of games on this page\n",
        "    df = pd.DataFrame(columns=[\"id\", \"name\", \"nrate\", \"pic_url\"], index=range(len(table)))  # DF to hold this pages results\n",
        "    \n",
        "    # Loop through each row and pull out the info for that game\n",
        "    for idx, row in enumerate(table):\n",
        "        # Row may or may not start with a \"boardgame rank\" link, if YES then strip it\n",
        "        links = row.find_all(\"a\")\n",
        "        if \"name\" in links[0].attrs.keys():\n",
        "            del links[0]\n",
        "        gamelink = links[1]  # Get the relative URL for the specific game\n",
        "        gameid = int(gamelink[\"href\"].split(\"/\")[2])  # Get the game ID by parsing the relative URL\n",
        "        gamename = gamelink.contents[0]  # Get the actual name of the game as the link contents\n",
        "        imlink = links[0]  # Get the URL for the game thumbnail\n",
        "        # thumbnail = imlink.contents[0][\"src\"]\n",
        "\n",
        "        # ratings_str = row.find_all(\"td\", attrs={\"class\": \"collection_bggrating\"})[2].contents[0]\n",
        "        # nratings = int(\"\".join(ratings_str.split()))\n",
        "\n",
        "        df.iloc[idx, :] = [gameid]\n",
        "\n",
        "    # Concatenate the results of this page to the master dataframe\n",
        "    min_nrate = df[\"nrate\"].min()  # The smallest number of ratings of any game on the page\n",
        "    print(\"Page %i scraped, minimum number of ratings was %i\" % (npage, min_nrate))\n",
        "    df_all = pd.concat([df_all, df], axis=0)\n",
        "    i =  len(df_all.index)\n",
        "    print(\"Number of games scraped is %i\" % i)\n",
        "    npage += 1\n",
        "    sleep(2) # Keep the BGG server happy."
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Page 1 scraped, minimum number of ratings was 11\n",
            "Number of games scraped is 100\n",
            "Page 2 scraped, minimum number of ratings was 3\n",
            "Number of games scraped is 200\n",
            "Page 3 scraped, minimum number of ratings was 41\n",
            "Number of games scraped is 300\n",
            "Page 4 scraped, minimum number of ratings was 10\n",
            "Number of games scraped is 400\n",
            "Page 5 scraped, minimum number of ratings was 46\n",
            "Number of games scraped is 500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cippUz-wzYvF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df_all.copy()\n",
        "# Reset the index since we concatenated a bunch of DFs with the same index into one DF\n",
        "df.reset_index(inplace=True, drop=True)\n",
        "# Write the DF to .csv for future use\n",
        "df.to_csv(\"bgg_gamelist.csv\", index=False, encoding=\"utf-8\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObhE-KSaIYoF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_toy = df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjBFg09PRwpg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create a temporary dataframe with the right structure\n",
        "#batch = current batch number \n",
        "#batch_size = number of raws in the dataframe\n",
        "def df_temp(batch, batch_size):\n",
        "  #  df = pd.DataFrame(columns=['type', 'name', 'yearpublished', 'minplayers', 'maxplayers',\n",
        "  #      'playingtime', 'minplaytime', 'maxplaytime', 'minage', 'usersrated',\n",
        "  #      'average',  'owned',\n",
        "  #      'trading', 'wanting', 'wishing', 'numcomments',\n",
        "  #       'numweights', 'averageweight', 'links'], index=range(batch*batch_size, batch_size+batch*batch_size))\n",
        "   df = pd.DataFrame(index=range(batch*batch_size, batch_size+batch*batch_size))\n",
        "  \n",
        "   return df   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnrlARB8Ugm2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def slice_ids(df, batch, batch_size):\n",
        "  added_index = df.loc[(df.index >= batch*batch_size) & (df_toy.index < batch_size+batch*batch_size), ['id']]\n",
        "  return added_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CNSvUPgV07i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#requests current batch of xml's based on df's ids\n",
        "#should have \"id\" column\n",
        "def request_df_xml(df):\n",
        "  id_strs = [str(gid) for gid in df[\"id\"]]\n",
        "  gameids = \",\".join(id_strs)\n",
        "  sleep(1.5)  # Keep the server happy\n",
        "  r = request(\"http://www.boardgamegeek.com/xmlapi2/thing?id=%s&stats=1\" % gameids)\n",
        "  return r"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIYm8qOqX1W2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add_values_xml_to_df(r, df):\n",
        "  soup = BeautifulSoup(r.text, \"xml\")\n",
        "  items = soup.find_all('item')\n",
        "  # print(len(items))\n",
        "  gtype = soup.find_all(\"type\")\n",
        "  name = soup.find_all(\"name\", {\"type\":\"primary\"})\n",
        "  yearpublished = soup.find_all (\"yearpublished\")\n",
        "  minplayers = soup.find_all (\"minplayers\")\n",
        "  maxplayers = soup.find_all (\"maxplayers\")\n",
        "  playingtime = soup.find_all (\"playingtime\")\n",
        "  minplaytime = soup.find_all (\"minplaytime\")\n",
        "  maxplaytime = soup.find_all (\"maxplaytime\")\n",
        "  minage = soup.find_all(\"minage\")\n",
        "  users_rated = soup.find_all(\"usersrated\")\n",
        "  average_rating = soup.find_all(\"average\")\n",
        "  total_owners = soup.find_all (\"owned\")\n",
        "  total_traders = soup.find_all(\"trading\")\n",
        "  total_wanters = soup.find_all(\"wanting\")\n",
        "  total_wishers = soup.find_all(\"wishing\")\n",
        "  total_comments = soup.find_all(\"numcomments\")\n",
        "  total_weights = soup.find_all(\"numweights\")\n",
        "  average_weight = soup.find_all (\"averageweight\")\n",
        "  links= []\n",
        "  for item in items: \n",
        "    # link.append(items[item])\n",
        "    links.append(item.findChildren(\"link\", recursive = \"False\"))\n",
        "    \n",
        "  # print(len(links))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wz-LG3vUC8pV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_temp_df(r):\n",
        "  soup = BeautifulSoup(r.text, \"xml\")\n",
        "  list_all_games = soup.find_all('item')\n",
        "  items = soup.find_all('item')\n",
        "  data  = {\n",
        "      'gameid': [],\n",
        "      'gametype':[],\n",
        "      'name': [],\n",
        "      'yearpublished': [],\n",
        "      'minplayers': [],\n",
        "      \"maxplayers\": [],\n",
        "      'playingtime': [],\n",
        "      'minplaytime': [],\n",
        "      'maxplaytime': [],\n",
        "      'minage': [],\n",
        "      'usersrated': [],\n",
        "      'average': [],\n",
        "      'owned': [],\n",
        "      'trading': [],\n",
        "      'wanting': [],\n",
        "      'wishing': [],\n",
        "      'numcomments': [],\n",
        "      'numweights': [],\n",
        "      'averageweight': [],\n",
        "      'categories':[],\n",
        "      'mechanics':[],\n",
        "      'designers':[],\n",
        "      'ranksubtypes': [],\n",
        "      'rankfamilies': [],\n",
        "      'families':[],\n",
        "      'expansions':[],\n",
        "      'implementations':[],\n",
        "      'publishers': []\n",
        "  }\n",
        "  for item in items: \n",
        "    # link.append(items[item])\n",
        "    gameid = item['id']\n",
        "    gametype = item['type']\n",
        "    name = item.findChild(\"name\", {\"type\":\"primary\"})['value']\n",
        "    yearpublished = item.findChild(\"yearpublished\")['value']\n",
        "    minplayers = item.findChild(\"minplayers\")['value']\n",
        "    maxplayers = item.findChild(\"maxplayers\")['value']\n",
        "    playingtime = item.findChild(\"playingtime\")['value']\n",
        "    minplaytime = item.findChild(\"minplaytime\")['value']\n",
        "    maxplaytime = item.findChild(\"maxplaytime\")['value']\n",
        "    minage = item.findChild(\"minage\")['value']\n",
        "    usersrated = item.findChild(\"usersrated\")['value']\n",
        "    average = item.findChild(\"average\")['value']\n",
        "    owned = item.findChild(\"owned\")['value']\n",
        "    trading = item.findChild(\"trading\")['value']\n",
        "    wanting = item.findChild(\"wanting\")['value']\n",
        "    wishing = item.findChild(\"wishing\")['value']\n",
        "    numcomments = item.findChild(\"numcomments\")['value']\n",
        "    numweights = item.findChild(\"numweights\")['value']\n",
        "    averageweight = item.findChild(\"averageweight\")['value']\n",
        "    categories = item.findChildren(\"link\", {\"type\": \"boardgamecategory\"})\n",
        "    mechanics = item.findChildren(\"link\", {\"type\": \"boardgamemechanic\"})\n",
        "    designers = item.findChildren(\"link\", {\"type\": \"boardgamedesigner\"})\n",
        "    subtypes = item.findChildren(\"rank\",{\"type\": \"subtype\"})\n",
        "    rankfamilies = item.findChildren(\"rank\", {\"type\": \"family\"})\n",
        "    families = item.findChildren(\"link\", {\"type\":\"boardgamefamily\"})\n",
        "    expansions = item.findChildren(\"link\", {\"type\":\"boardgameexpansion\"})\n",
        "    implementations = item.findChildren(\"link\", {\"type\": \"boardgameimplementation\"})\n",
        "    publishers = item.findChildren(\"link\", {\"type\":\"boardgamepublisher\"})\n",
        "\n",
        "    # print(categories)\n",
        "    categories_list = []\n",
        "    mechanics_list = []\n",
        "    designers_list = []\n",
        "    subtypes_list = []\n",
        "    rankfamilies_list = []\n",
        "    families_list = []\n",
        "    expansions_list = []\n",
        "    implementations_list = []\n",
        "    publishers_list = []\n",
        "    # НЕ ПОНЯТНО, КАКИЕ ИМЕННО VALUES ВЫТЯГИВАТЬ, IDS ИЛИ NAMES ИЛИ И ТО И ТО :((\n",
        "    for category in categories:\n",
        "      categories_list.append(category['value'])\n",
        "    for mechanic in mechanics:\n",
        "      mechanics_list.append(mechanic['value'])\n",
        "    for designer in designers:\n",
        "      designers_list.append(designer['value'])\n",
        "    for subtype in subtypes:\n",
        "      subtypes_list.append(subtype['name'])   \n",
        "    for family in rankfamilies:\n",
        "      rankfamilies_list.append(family['name'])  \n",
        "    for family in families:\n",
        "      families_list.append(family['value'])\n",
        "    for expansion in expansions:\n",
        "      expansions_list.append(expansion['id'])   \n",
        "    for implementation in implementations: \n",
        "      implementations_list.append(implementation['id'])   \n",
        "    for publisher in publishers: \n",
        "      publishers_list.append(publisher['id'])    \n",
        "    data['gameid'].append(gameid)\n",
        "    data['gametype'].append(gametype)\n",
        "    data['name'].append(name)\n",
        "    data['yearpublished'].append(yearpublished)\n",
        "    data['minplayers'].append(minplayers)\n",
        "    data['maxplayers'].append(maxplayers)\n",
        "    data['playingtime'].append(playingtime)\n",
        "    data['minplaytime'].append(minplaytime)\n",
        "    data['maxplaytime'].append(maxplaytime)\n",
        "    data['minage'].append(minage)\n",
        "    data['usersrated'].append(usersrated)\n",
        "    data['average'].append(average)\n",
        "    data['owned'].append(owned)\n",
        "    data['trading'].append(trading)\n",
        "    data['wanting'].append(wanting)\n",
        "    data['wishing'].append(wishing)\n",
        "    data['numcomments'].append(numcomments)\n",
        "    data['numweights'].append(numweights)\n",
        "    data['averageweight'].append(averageweight)\n",
        "    data['categories'].append(categories_list if categories_list else '') #is it safe to use empty string as a placeholder?\n",
        "    data['mechanics'].append(mechanics_list if mechanics_list else '')\n",
        "    data['designers'].append(designers_list if designers_list else '')\n",
        "    data['ranksubtypes'].append(subtypes_list if subtypes_list else '')\n",
        "    data['rankfamilies'].append(rankfamilies_list if rankfamilies_list else '')\n",
        "    data['families'].append(families_list if families_list else '')\n",
        "    data['expansions'].append(expansions_list if expansions_list else '')\n",
        "    data['implementations'].append(implementations_list if implementations_list else '')\n",
        "    data['publishers'].append(publishers_list if publishers_list else '')\n",
        "\n",
        "  table = pd.DataFrame.from_dict(data)\n",
        "  return table"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1RNXqmq7s3Tx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        },
        "outputId": "87d75e2d-c1a1-4dc5-829a-5cb6c733569b"
      },
      "source": [
        "# Gathering all METADATA from all games in toy data set\n",
        "#############################################################\n",
        "# Get the metadata for all games, but do it in chunks of 250 games\n",
        "df_meta_all = pd.DataFrame()\n",
        "batch_size = 250\n",
        "for batch, group in df_toy.groupby(np.arange(len(df_toy))//batch_size):\n",
        "      print(\"Processed ratings for batch #%i of games.\" % (batch))\n",
        "      print(group)\n",
        "   \n",
        "    # Initialize a DF to hold all the responses for this chunk of games\n",
        "      df_meta = df_temp(batch, batch_size)\n",
        "      # Set the next chunk of the DF \"gameid\" column using the list of game IDs\n",
        "      added_index = slice_ids(df_toy, batch, batch_size)\n",
        "      df_meta = pd.concat([df_meta, added_index], axis = 1)\n",
        "      r = request_df_xml(df_meta)\n",
        "      temp = create_temp_df(r)\n",
        "      df_meta_all = df_meta_all.append(temp, ignore_index=True, sort = False)\n",
        "# print(df_meta_all)      \n",
        "df_meta_all.to_csv('/content/gdrive/My Drive/Thesis/test.csv')\n",
        "\n",
        " "
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processed ratings for batch #0 of games.\n",
            "         id    name   nrate pic_url\n",
            "0        13      13      13      13\n",
            "1       822     822     822     822\n",
            "2     30549   30549   30549   30549\n",
            "3     68448   68448   68448   68448\n",
            "4     36218   36218   36218   36218\n",
            "..      ...     ...     ...     ...\n",
            "245     483     483     483     483\n",
            "246  115746  115746  115746  115746\n",
            "247  155362  155362  155362  155362\n",
            "248     811     811     811     811\n",
            "249      41      41      41      41\n",
            "\n",
            "[250 rows x 4 columns]\n",
            "Processed ratings for batch #1 of games.\n",
            "         id    name   nrate pic_url\n",
            "250  172818  172818  172818  172818\n",
            "251  224517  224517  224517  224517\n",
            "252  236457  236457  236457  236457\n",
            "253   46213   46213   46213   46213\n",
            "254   66188   66188   66188   66188\n",
            "..      ...     ...     ...     ...\n",
            "495    2389    2389    2389    2389\n",
            "496  232043  232043  232043  232043\n",
            "497   36932   36932   36932   36932\n",
            "498   82222   82222   82222   82222\n",
            "499  179275  179275  179275  179275\n",
            "\n",
            "[250 rows x 4 columns]\n",
            "     gameid  ...                                         publishers\n",
            "0        13  ...  [37, 267, 4304, 7340, 6784, 7162, 4358, 31418,...\n",
            "1       822  ...  [133, 267, 4304, 9074, 6784, 7162, 24631, 2366...\n",
            "2     30549  ...  [538, 3320, 4304, 157, 42032, 15889, 7162, 236...\n",
            "3     68448  ...  [4384, 23043, 157, 15889, 15605, 8820, 1391, 6...\n",
            "4     36218  ...  [3, 267, 4304, 9074, 11043, 24631, 2366, 5657,...\n",
            "..      ...  ...                                                ...\n",
            "495    2389  ...  [171, 3320, 11388, 1017, 404, 33631, 9068, 298...\n",
            "496  232043  ...  [6760, 5022, 491, 26380, 1280, 19047, 8820, 84...\n",
            "497   36932  ...                                        [157, 7466]\n",
            "498   82222  ...                              [14439, 34801, 30677]\n",
            "499  179275  ...   [5407, 35928, 31815, 30713, 37959, 15906, 24844]\n",
            "\n",
            "[500 rows x 28 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}